<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Verbalize AI - Web Tester</title>
    <style>
        body { font-family: sans-serif; max-width: 800px; margin: 2rem auto; padding: 0 1rem; background: #f4f4f9; }
        .container { background: white; padding: 2rem; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        h2 { border-bottom: 2px solid #ddd; padding-bottom: 0.5rem; }
        .form-group { margin-bottom: 1rem; }
        label { display: block; margin-bottom: 0.5rem; font-weight: bold; }
        input, textarea, select { width: 100%; padding: 0.5rem; margin-bottom: 0.5rem; border: 1px solid #ccc; border-radius: 4px; }
        button { padding: 0.75rem 1.5rem; background: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer; font-size: 1rem; }
        button:disabled { background: #ccc; }
        button.stop { background: #dc3545; }
        
        #interview-area { margin-top: 2rem; display: none; }
        #chat-log { height: 300px; overflow-y: auto; border: 1px solid #eee; padding: 1rem; background: #fafafa; margin-bottom: 1rem; }
        .msg { margin-bottom: 0.5rem; padding: 0.5rem; border-radius: 4px; }
        .msg.user { background: #e3f2fd; text-align: right; margin-left: 20%; }
        .msg.ai { background: #e8f5e9; margin-right: 20%; }
        .status { font-weight: bold; color: #555; }
        .blinking { animation: blinker 1.5s linear infinite; color: red; }
        @keyframes blinker { 50% { opacity: 0; } }
    </style>
</head>
<body>

<div class="container">
    <h2>1. Setup Interview</h2>
    <div id="setup-form">
        <div class="form-group">
            <label>User ID (Email)</label>
            <input type="text" id="user_id" value="test_user@example.com">
        </div>
        <div class="form-group">
            <label>Job Role</label>
            <input type="text" id="job_role" value="Java Backend Engineer">
        </div>
        <div class="form-group">
            <label>Job Level</label>
            <select id="job_level">
                <option value="Junior">Junior</option>
                <option value="Senior" selected>Senior</option>
            </select>
        </div>
        <div class="form-group">
            <label>Job Description</label>
            <textarea id="job_desc" rows="3">Must know Java, Spring Boot, Microservices, and AWS.</textarea>
        </div>
        <div class="form-group">
            <label>Resume (PDF)</label>
            <input type="file" id="resume_file" accept=".pdf">
        </div>
        <button onclick="initInterview()" id="init-btn">Initialize Interview</button>
    </div>

    <div id="interview-area">
        <h2>2. Live Interview</h2>
        <div class="status" id="status-text">Connecting...</div>
        <div id="chat-log"></div>
        <div style="display: flex; gap: 10px;">
            <button onclick="startRecording()" id="start-btn">ðŸŽ¤ Start Speaking</button>
            <button onclick="stopRecording()" id="stop-btn" class="stop" disabled>ðŸ›‘ Stop Speaking</button>
            <button onclick="endInterview()" style="background: #333;">End Interview</button>
        </div>
    </div>
</div>

<script>
    let sessionId = null;
    let ws = null;
    let mediaRecorder = null;
    let audioQueue = [];
    let isPlaying = false;
    let audioContext = null; // For playing PCM/WAV from server

    const API_URL = "http://localhost:8000"; // Adjust if different

    // --- 1. INITIALIZE ---
    async function initInterview() {
        const userId = document.getElementById('user_id').value;
        const jobRole = document.getElementById('job_role').value;
        const jobLevel = document.getElementById('job_level').value;
        const jobDesc = document.getElementById('job_desc').value;
        const resumeFile = document.getElementById('resume_file').files[0];

        if (!resumeFile) return alert("Please upload a resume");

        const formData = new FormData();
        formData.append('user_id', userId);
        formData.append('job_role', jobRole);
        formData.append('job_level', jobLevel);
        formData.append('job_desc', jobDesc);
        formData.append('resume', resumeFile);

        document.getElementById('init-btn').disabled = true;
        document.getElementById('init-btn').innerText = "Uploading...";

        try {
            const res = await fetch(`${API_URL}/api/interview/init`, {
                method: 'POST',
                body: formData
            });
            const data = await res.json();
            
            if (data.session_id) {
                sessionId = data.session_id;
                document.getElementById('setup-form').style.display = 'none';
                document.getElementById('interview-area').style.display = 'block';
                connectWebSocket(sessionId);
            } else {
                alert("Error: " + JSON.stringify(data));
            }
        } catch (e) {
            alert("API Error: " + e.message);
        }
    }

    // --- 2. WEBSOCKET CONNECTION ---
    function connectWebSocket(sid) {
        const wsUrl = `ws://localhost:8000/ws/interview/${sid}`;
        ws = new WebSocket(wsUrl);
        ws.binaryType = 'arraybuffer'; // Critical for receiving audio

        ws.onopen = () => {
            document.getElementById('status-text').innerText = "Connected! Waiting for AI...";
        };

        ws.onmessage = async (event) => {
            const data = event.data;

            if (typeof data === "string") {
                // Handle JSON messages (Text transcripts/Controls)
                const msg = JSON.parse(data);
                
                if (msg.type === 'text' || msg.type === 'transcript') {
                    // Update Chat UI
                    appendMessage(msg.role || 'ai', msg.content);
                } else if (msg.type === 'control' && msg.action === 'end_interview') {
                    alert("The interviewer has ended the session.");
                    endInterview();
                }
                
            } else if (data instanceof ArrayBuffer) {
                // Handle Audio Bytes (Play them)
                audioQueue.push(data);
                playAudioQueue();
            }
        };

        ws.onclose = () => {
            document.getElementById('status-text').innerText = "Disconnected.";
        };
    }

    // --- 3. AUDIO RECORDING (BROWSER -> BACKEND) ---
    async function startRecording() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            
            // WebM/Opus is standard for browsers
            mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });

            mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0 && ws && ws.readyState === WebSocket.OPEN) {
                    ws.send(event.data); // Send blob directly
                }
            };

            // Send chunks every 250ms for near real-time latency
            mediaRecorder.start(250); 
            
            document.getElementById('start-btn').disabled = true;
            document.getElementById('stop-btn').disabled = false;
            document.getElementById('status-text').innerHTML = "<span class='blinking'>ðŸ”´ Listening...</span>";
            
        } catch (err) {
            console.error("Mic Error:", err);
            alert("Microphone access denied");
        }
    }

    function stopRecording() {
        if (mediaRecorder) {
            mediaRecorder.stop();
            document.getElementById('start-btn').disabled = false;
            document.getElementById('stop-btn').disabled = true;
            document.getElementById('status-text').innerText = "Processing...";
        }
    }

    // --- 4. AUDIO PLAYBACK (BACKEND -> BROWSER) ---
    // Simple queue to play audio chunks sequentially
    async function playAudioQueue() {
        if (isPlaying || audioQueue.length === 0) return;
        
        isPlaying = true;
        const audioData = audioQueue.shift();
        
        // Create a blob from the raw bytes (Assuming backend sends WAV/PCM wrapped)
        // Note: Deepgram 'container=wav' adds headers, so browsers can play it as a Blob.
        const blob = new Blob([audioData], { type: 'audio/wav' });
        const url = URL.createObjectURL(blob);
        const audio = new Audio(url);
        
        audio.onended = () => {
            isPlaying = false;
            URL.revokeObjectURL(url); // Cleanup
            playAudioQueue(); // Play next chunk
        };
        
        try {
            await audio.play();
        } catch (e) {
            console.error("Playback error", e);
            isPlaying = false;
            playAudioQueue();
        }
    }

    // --- UI HELPERS ---
    function appendMessage(role, text) {
        const log = document.getElementById('chat-log');
        const div = document.createElement('div');
        div.className = `msg ${role === 'user' ? 'user' : 'ai'}`;
        div.innerHTML = `<strong>${role === 'user' ? 'You' : 'AI'}:</strong> ${text}`;
        log.appendChild(div);
        log.scrollTop = log.scrollHeight;
    }

    function endInterview() {
        if(ws) ws.close();
        document.getElementById('status-text').innerText = "Session Ended. Check backend logs for Report.";
    }
</script>

</body>
</html>